HARDWARE OVERHEADS:

- 162-166 cycles of overhead for simple protection level crossing

- 312 cycles of overhead for 2 protection level bounces

- 860 cycles when a single write to cr3 with the address of the
  current page tables (clear TLB and update processor state for new
  page tables).  This jumps to 1110 cycles when 2 writes to cr3 are
  introduced, one in each direction.

LINUX MICROBENCHMARKS:

- syscall for gettimeofday(NULL, NULL) is 502 cycles, or 0.209
  microseconds on vanilla kernel 2.6.22

- same syscall is 1463 cycles, or 0.61 microseconds on CentOS
  2.6.18-53.1.14.el5, a Fedora Redhat derivative

- sched_yield* between two highest priority processes in the first linux
  system is 3089, or 1.287 microseconds.

- sched_yield* between processes the redhat derivative: 4448.927 or
  1.97 microseconds

- sched_yield* between two threads using NPTL 2.5 on vanilla linux
  takes 1903 cycles, or 0.795 microseconds.

- sched_yield* between two threads using NPTL 2.5 on the fedora
  derivative takes 3380 cycles, or 1.408 microseconds

- IPC between two high priority processes on the vanilla Linux using
  pipes takes 15367 cycles, or 6.403 microseconds.

- IPC using pipes on the redhat derivative takes 30158 cycles or
  12.566 microseconds.

- Signal delivery within the same process by executing a tight loop
  around kill sending a sigusr1 to a handler takes 4377 cycles on
  vanilla.  6000 on fedora.

- uncontended lock/unlock of futex is 411 cycles

* experiments conducted with the two threads at highest priority on
the system, and it is ensured that the # of context switches induced
by sched_yield is as expected by monitoring /proc/stats (ctxt %d)

COMPOSITE OS SYSTEM MICROBENCHMARKS:

- IPC takes 1629 cycles or 0.679 microseconds

- Thread switch WITHOUT accounting takes 529 cycles, or .22
  microseconds without scheduler structures/eval in component.  With
  those overheads, it takes 688 cycles, or 0.287 microseconds for a
  thread switch.

- Thread switch with actual component scheduler involvement
  (run-queues, etc...) and WITH accounting takes 976 cycles, or 0.407
  microseconds.  The overhead is due to 1) 80 cycles of overhead from
  the rdtsc instruction, and 2) memory accesses from the
  thd_sched_info structs (1 cache miss for all accesses), 1 accessing
  the scheduler (spd) structure to update the head of the event list,
  for each scheduler, and 1 cache miss to point the previous event to
  the current, 1 cache miss to update the current, for each scheduler.

- Making a brand that is ultimately delayed (not immediately executed
  due to lesser urgency), but not because the upcall is pending, when
  using brand_upcall takes 0.19 microseconds (458 cycles).

- Make a brand to a brand with an active upcall, resulting in an
  incriment of the pending count: 340 cycles or 0.141 microseconds.

- Immediate brand execution due to higher urgency and a direct return
  to the calling thread (automatic return due to interrupted_thread)
  takes 1.43 microseconds or 3442 cycles.  Cost of brand_next_thread
  to determine if we should run the upcall thread alone is 1306
  cycles, and brand_execution_completion is 940.  Take that with the
  1110 cycles of hardware overhead and you have 3356, which is almost
  right on the dot.

- Executing a pending upcall takes 804 cycles, or 0.335 microseconds.

* It can be emphasized that at very low levels where brands are known
  to always have presidence (irq raise), brands can be much quicker,
  always executing the branded thread.

- Executing a brand where the scheduler is upcalled into to decide if
  we should run the upcall now or later, and is then upcalled into
  when the upcall is done takes 9410 cycles or 3.92 microseconds.
  This is faster than the 3*3442 = 10326 for 3 branded upcalls
  (i.e. each upcall is 305 cycles faster than if it was a brand), but
  not faster than the comparible operation of 1 branded upcall.  This
  overhead includes any overhead that two invocations of the fp
  scheduler adds (seems like (976-688=288*2=) 576 cycles from
  above). It should be pointed out that even if this implementation
  isn't optimal, the hardware overhead here is significant: at least
  2220.  Additionally, switching between threads twice, though
  inexpensive, adds to the total.

- When a brand is attempted and the scheduler is upcalled into (not
  using intelligent brand mechanism) and the upcall thread has a
  lesser priority, thus the brander is switched back to (two page
  table switches) immediately, the overhead is 5027 cycles or 2.07
  microseconds, which, again, includes 1 scheduler's overhead, ~288.
  This is compared to the "making a brand that is ultimately delayed"
  here.  Note that if we don't execute brands immediately often, then
  it is probably that there will be pending brands when we do execute
  it.  This significantly lowers the cost here to the cost of a brand
  made when upcall is active (above @ 340 cycles).

- Uncontended scheduler lock on Composite takes 26 cycles.
